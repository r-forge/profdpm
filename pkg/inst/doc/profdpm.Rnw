\documentclass[article]{jss}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\VignetteIndexEntry{profdpm}
%% almost as usual
\author{Matthew S. Shotwell\\Medical University of South Carolina}
\title{\pkg{profdpm}: An \proglang{R} Package for MAP Estimation in a Class of Product Partition Models}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Matthew S. Shotwell} %% comma-separated
\Plaintitle{profdpm: An R Package for MAP Estimation in a Class of Product Partition Models} %% without formatting
%\Shorttitle{MAP Estimation in a Class of Product Partition Models} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
The \pkg{profdpm} package facilitates profile inference, or inference at the posterior mode for a class of product partition models (PPM). The Dirichlet process mixture is represented as a specific case in this class, and is the default. The PPM is implemented for linear models and multivariate binary models. Several methods are implemented to search for the maximum posterior estimate of the cluster partition in the PPM. This article introduces the relevant theory, discusses the \proglang{R} and \proglang{C} implementation, and gives examples of the high level functionality.
}
\Keywords{product partition model, MAP estimate, clustering, \proglang{R}, \proglang{C}}
\Plainkeywords{product partition model, MAP estimate, clustering, R, C} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Matthew S. Shotwell\\
  Division of Biostatistics and Epidemiology\\
  Medical University of South Carolina\\
  135 Canon St. Charleston, SC, USA\\
  E-mail: \email{shotwelm@musc.edu}\\
  URL: \url{http://biostatmatt.com}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsbsy}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\bu}{\boldsymbol{u}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\bXp}{\boldsymbol{X}^{\prime}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bI}{\boldsymbol{I}}
\newcommand{\byp}{\boldsymbol{y}^{\prime}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bm}{\boldsymbol{m}}
\newcommand{\bS}{\boldsymbol{S}}

\begin{document}

\section[Intro]{Introduction}
\pkg{profdpm} is an extension package for the \proglang{R} language and environment for statistical computing \citep{R2010}. This package facilitates profile inference, or inference at the posterior mode in a class of product partition models (PPM). The class of PPMs considered herein was motivated by, and has as a special case, a PPM formulation of the Dirichlet process mixture. The \pkg{profdpm} package consists of two model-fitting functions, \code{profBinary} and \code{profLinear}, and one function \code{pci} that computes several metrics of agreement between two partitions.

The remainder of this article proceeds as follows: the relevant theory of product partition models is discussed in section \ref{PPMs}, \proglang{R} functions and the underlying \proglang{C} methods are outlined in section \ref{Code}, and examples are presented in sections \ref{Examples:profLinear} and \ref{Examples:profBinary}. Section \ref{Extensions} gives a short discussion of potential extensions to the \pkg{profdpm} package.\\

\section[PPMs]{Product partition models} \label{PPMs}
Consider the following hierarchical Bayesian model for a collection of possibly multivariate observations $\by = \{y_1, \ldots, y_n\}$:
\begin{eqnarray}
y_i | z_i = k, \phi_k & \sim & f(y_i|\phi_k) \nonumber \\
\phi_k & \sim & \pi_{\phi}(\phi_k) \nonumber \\
\bz & \sim & \pi_{\bz}(\bz) \propto \prod_{k=1}^r c_k(\bz), \nonumber
\end{eqnarray}
where $\bz = \{z_1, \ldots, z_n\}$ is a collection of cluster membership variables such that $z_i = k$ indicates observation $i$ is a member of cluster $k$. The collection $\bz$ represents a partition of $\by$ into $r$ clusters, identified by the $r$ unique values among $\bz$. The values of $\bz$ are not important, as long as they are distinct. For simplicity, the positive integers are used to enumerate the distinct values. The function $f$ is a probability density indexed by parameter $\phi_k$. For $k = 1,\ldots,r$, $\phi_k$ are independently distributed according to prior density $\pi_{\phi}$. The prior mass function $\pi_{\bz}$ is proportional to a product of {\it cohesion} functions $c_k$. The cohesion functions are used to specify the prior distribution and prior belief about the data partition. The Dirichlet process mixture has a PPM representation when $c_k(\bz) = \alpha\Gamma(n_k)$, where $\alpha$ is a scalar `precision' parameter, $\Gamma$ is the gamma function, and $n_k$ represents the number of observations assigned to the $k^{th}$ cluster. Alternative cohesions yield other well-known process mixtures \citep[see][for a partial listing]{LauGreen2007}. The \pkg{profdpm} package extends the Dirichlet process mixture cohesion to include a scalar `balance' parameter $\lambda$, such that $c_k(\bz) = \alpha\Gamma(n_k)^{\lambda}$. The value of $\lambda$ affects the balance of partition cluster sizes $\{n_1, \ldots, n_r\}$. The posterior distribution over the cluster partition is proportional to the product
\begin{eqnarray}
p(\bz|\by) \propto \prod_{k=1}^r c_k(\bz) \int L(\phi_k|\by) \pi_{\phi}(\phi_k) d\phi_k , \nonumber
\end{eqnarray}
where $L(\phi_k|\by) = \prod_{i=1}^n f(y_i|\phi_k)^{I(z_i=k)}$ is the cluster-specific likelihood. Hence, the product partition model is conjugate in the sense that both prior and posterior may be written as a product of cluster-specific terms. The product partition model is attributed to \citet{Hartigan1990} and \citet{BarryHartigan1992}.

A maximum {\it a posteriori} (MAP) estimate of the data partition variable $\bz$ is often computed when the PPM is used for clustering. However, the principal difficulty with partition models is the size of the partition space (see the Bell number). Hence, computing the MAP estimate using enumerative methods is not practical.

The \pkg{profdpm} package utilizes three methods to approximate the MAP estimate in an iterative fashion. The first method is the agglomerative method of \citet{Ward1963}, later used by \citet{Heard2005} in the context of Dirichlet process mixtures. The agglomerative method is (usually) the fastest of the three implemented methods, but does not yield arbitrarily precise approximations to the MAP estimate.

The second method is the Polya urn Gibbs sampler of \citet{MacEachern1994}, \citet{BushMacEachern1996}, and \citet{MacEachernMuller1998}. The Gibbs sampler sequentially samples from the full conditional distributions having mass functions of the form $p(z_i|\bz_{-i},\by)$, where $\bz_{-i}$ is the collection of cluster membership variables with the exception of $z_i$. The Gibbs method produces a consistent sequence of MAP estimates by selecting the sample MAP estimate following each iteration. However, the Polya urn Gibbs sampler is prone to poor mixing in the partition space, and is computationally intensive.

The last method is an iterative stochastic search utilizing `explode' and `merge' operations on the clusters of a partition. At the explode step, a randomly selected subset of observations are redistributed uniformly at random to an existing or new cluster. Each of the exploded observations are then merged with one of the existing clusters in a sequentially optimal fashion. The explode-merge method is motivated by the split-merge Metropolis Hastings algorithms of \citet{GreenRichardson2001}, and \citet{JainNeal2004, JainNeal2007}. This method utilizes a Markov chain to approximate the MAP estimate, but does not sample from the posterior distribution over the cluster partition. Hence, the explode-merge method avoids the complexity and computational expense of ensuring the chain is ergodic. 

Profile inference about the parameter $\phi_k$ is conditional on an estimate of the data partition. Conditional on the partition estimate, $\{\phi_1, \ldots, \phi_r\}$ are independent {\it a posteriori}, and distributed according to 
\begin{displaymath}
p(\phi_k | \by, \hat{\bz}) = \int L(\phi_k|\by) \pi_{\phi}(\phi_k) d\phi_k.
\end{displaymath}
The likelihood and prior over $\phi_k$ are often selected to be conjugate in $\phi_k$, where this integral has closed form. The PPMs used in the \pkg{profdpm} package are two such models.

\section[Code]{Programming strategy} \label{Code}

The \pkg{profdpm} package computes a MAP estimate for two types of PPMs, corresponding to the \code{profLinear} and \code{profBinary} functions. Both functions accept data and model fitting arguments, and return an estimate of the cluster partition and other information necessary for profile inference. 

\subsection[R code]{\proglang{R} code}

The \code{profLinear} function fits a product partition of conjugate normal linear models:
\begin{eqnarray}
y_i | \bx_i, z_i = k, \bmu_k, \tau_k & \sim & N(\bx^{\prime}\bmu_k, \tau_k) \nonumber \\
\bmu_k, \tau_k & \sim & N_qG(\bm_0, s_0I_q, a_0/2, 2/b_0) \nonumber \\
\bz & \sim & \pi_{\bz}(\bz) \propto \prod_{k=1}^r \alpha \Gamma(n_k)^{\lambda},
\end{eqnarray}
where $y_i$ is a continuous scalar observation, $\bx_i$ is a covariate vector, $N$ represents the normal distribution with mean $\bx^{\prime}\bmu_k$ and precision $\tau_k$, and $N_qG$ represents the $(q+1)$-variate normal-gamma distribution with mean $\bm_0$, precision matrix $\tau s_0I_q$, shape $a_0/2$, and scale $2/b_0$. The prior parameters $\bm_0$, $s_0$, $a_0$, $b_0$, $\alpha$, and $\lambda$ may be specified as arguments to the \code{profLinear} function. Conditional on an estimated partition, the pairs $\{(\bmu_1, \tau_1), \ldots, (\bmu_r, \tau_r)\}$ are independent {\it a posteriori} and distributed according to the $(q+1)$-variate normal gamma distribution with mean $\bm_k$, precision matrix $\tau\bS_k$, shape $a_k/2$, and scale $2/b_k$. In addition to the estimated partition, the posterior statistics $\bm_k$, $\bS_k$, $a_k$, and $b_k$ are returned by \code{profLinear} for each cluster.

The \code{profBinary} function fits a product partition of conjugate binary models:
\begin{eqnarray}
y_{ij} | z_i = k, \phi_{kj} & \sim & B(\phi_{kj}) \nonumber \\
\phi_{kj} & \sim & b(a_0, b_0) \nonumber \\
\bz & \sim & \pi_{\bz}(\bz) \propto \prod_{k=1}^r \alpha \Gamma(n_k)^{\lambda},
\end{eqnarray}
where $y_{ij}$ for $j = 1,\ldots,q$ is the $j^{th}$ binary observation for a subject $i$, $B$ represents the Bernoulli distribution with probability $\phi_{kj}$, and $b$ represents the beta distribution with shape parameters $a_0$ and $b_0$. Conditional on an estimated partition, $\phi_{kj}$ is independently beta distributed {\it a posteriori} with shape parameters $a_{kj}$ and $b_{kj}$. The \code{profBinary} function returns the estimated cluster partition as well as the posterior statistics $a_{kj}$ and $b_{kj}$.

\subsection[C code]{\proglang{C} code}
The three methods used to compute a MAP estimate of the PPM partition (see section \ref{PPMs}) in the \pkg{profdpm} package are implemented in \proglang{C}. Each utilizes a Markov-like process. That is, a partition state is initialized, and then updated sequentially, where the updated state depends on the previous state. Each of the MAP estimation routines may be decomposed into two simple operations on the initialized partition state: reassigning a single observation from one cluster to another, and computing the posterior mass at the given partition state. Manipulating a partition/model state with simple operations is strategic. By implementing a few simple operations efficiently, the programmer is free to focus on simplicity and correctness in implementing more complex routines. The methods for MAP estimation are generically applicable to all product partition models, provided the simple operations are defined. The task of applying the methods generically involves writing functions that perform these simple operations for each supported PPM type ({\it e.g.} for product partitions of linear or binary models). In practice, since the partition state must be initialized, the `move' operation is further decomposed into operations that add and remove single observations to and from a cluster.

Computing posterior mass at a given partition state is greatly simplified by selecting a conjugate likelihood and prior, because the posterior mass function over the cluster partition then has a simplified form. The posterior mass function in a PPM is a product of cluster specific terms. Hence, the simple operation of moving a single observation from one cluster to another affects, at most, two of these terms. The \proglang{C} implementation of \pkg{profdpm} optimizes the posterior mass calculation by computing only the terms associated with clusters that had changed since the previous calculation. This is implemented by decomposing the posterior mass calculation into operations that compute only the cluster-specific terms, and a single operation that computes the cluster-independent terms. 

Each supported PPM has an associated \proglang{C} structure containing data arrays, variables for model fitting parameters, and pointers to functions that perform the simple operations necessary for MAP estimation. These structures hold the partition state, and their references are passed to and from the MAP estimation methods. Additional PPMs may be supported by defining new structures and the associated functions to perform necessary operations on the partition state. Readers interested in extending the \pkg{profdpm} package to support additional PPMs are encouraged to explore the \pkg{profdpm} source code, available via the Comprehensive R Archive Network (CRAN). The PPM of binary models implementation (\code{src/pdpmbm.c}) is the simplest of the two implemented models.

\section[Examples]{Examples: \code{profLinear}} \label{Examples:profLinear}
This code example simulates a dataset consisting of three linear subgroups. The goal of this analysis is to recover the subgroup partition and perform profile inference on the slope parameter of each cluster. The following \proglang{R} snippet creates and fits the simulated dataset.
<<echo=false>>=
set.seed(42)
options(prompt = "R> ")
options(continue = "R+ ")
@
<<>>=
#simulate data with 3 linear subgroups
x <- as.matrix(runif(99))
y <- c(0*x[1:33], 10*x[34:66], 20*x[67:99]) + rnorm(99)

#estimate linear partition
library("profdpm")
fit1 <- profLinear(y, x)
@
Figure~\ref{fig:sim1} presents the simulated data in a scatterplot. For each cluster identified in the estimated partition, the (profile) posterior mean slope is represented by a dashed line with intercept zero. A $95\%$ credible interval for the slope is represented by two lines with slopes corresponding to the $0.025$ and $0.975$ quantiles of the (profile) posterior distribution over the slope parameter. These quantiles are computed using a parametric bootstrap.
\begin{center}
\begin{figure}
<<fig=TRUE>>=
plot(x, y)
#plot mean line, bootstrap 95% credible lines
B <- 10000 #bootstrap size
attach(fit1, warn.conflicts=FALSE)
for(i in 1:length(m)) {
    abline(a=0,b=m[[i]],lty=2, col=i)
    tboot <- rgamma(B, a[[i]]/2, b[[i]]/2)
    mboot <- rnorm(B, m[[i]], 1/sqrt(s[[i]]*tboot))
    qboot <- quantile(mboot, probs=c(0.025, 0.975))
    abline(a=0,b=qboot[1], col=i)
    abline(a=0,b=qboot[2], col=i)
}
detach(fit1)
@
\caption{Scatterplot of three simulated linear subgroups. Mean estimates (dashed) and $95\%$ credible intervals (solid) are presented, conditional on the estimated data partition. \label{fig:sim1}}
\end{figure}
\end{center}

The \code{profLinear} function may also accommodate non-linear subgroups, under suitable transformations of the covariate. The following example simulates two subgroups with \code{sinc} mean functions.
<<>>=
#simulate data with 2 non-linear subgroups
sinc <- function(x) sin(pi*x)/(pi*x)
x <- as.matrix(runif(100))
y <- c(20*sinc(2*x[1:50]), 20*sinc(5*x[51:100]))+rnorm(100)
X <- cbind(sinc(2*x), sinc(5*x))

#estimate partition
library("profdpm")
fit2 <- profLinear(y, X)
@

The following code block generates a scatterplot of the simulated data similar to that in Figure~\ref{fig:sim2}. The scatterplot is overlaid with the profile posterior mean functions for each cluster. A pointwise $95\%$ credible interval for each mean function is computed using a parametric bootstrap.
\begin{center}
\begin{figure}
<<fig=TRUE>>=
plot(x, y)
#plot mean curve, bootstrap 95% credible lines
B <- 10000 #bootstrap size
attach(fit2, warn.conflicts=FALSE)
for(i in 1:length(m)) {
    xplot <- seq(0.001, 1, length.out=100)
    mplot <- cbind(sinc(2*xplot), sinc(5*xplot)) %*% m[[i]]
    tboot <- rgamma(B, a[[i]]/2, b[[i]]/2)
    mboot <- matrix(rnorm(2*B, 0, 1/sqrt(tboot)),ncol=2)
    mboot <- mboot %*% chol(solve(s[[i]])) 
    mboot <- mboot + outer(rep(1,B),m[[i]])
    Xplot <- cbind(sinc(2*xplot), sinc(5*xplot))
    Mplot <- mboot %*% t(Xplot)
    Cred  <- apply(Mplot, 2, quantile, probs=c(0.025,0.975))
    lines(xplot, mplot, col=i, lty=2)
    lines(xplot, Cred[1,], col=i, lty=1)
    lines(xplot, Cred[2,], col=i, lty=1)
}
detach(fit2)
@
\caption{Scatterplot of two simulated nonlinear subgroups. Mean estimates (dashed) and $95\%$ credible intervals (solid) are presented, conditional on the estimated data partition. \label{fig:sim2}}
\end{figure}
\end{center}

In each of the above examples, the \code{pci} function may be used to compute several measures of agreement between the simulated and estimated partitions. The following demonstrates the use of \code{pci}.
<<>>=
simulatedPart1 <- rep(1:3, rep(33,3))
estimatedPart1 <- fit1$clust
pci(simulatedPart1, estimatedPart1)
simulatedPart2 <- rep(1:2, rep(50,2))
estimatedPart2 <- fit2$clust
pci(simulatedPart2, estimatedPart2)
@

The first value in the vector returned by \code{pci} corresponds to the \citet{Rand1971} index for the two partitions. This statistic enumerates the proportion of observations pairs that are clustered concordantly in the two partitions. A Rand index value of one indicates perfect agreement. Inference about these statistics is difficult, partly because a null hypothesis about the partition is rarely well defined. However, the \code{pci} function may be used to construct bootstrap tests using the Rand index (or another index) as a test statistic.

In both of the previous examples, every observation is clustered individually. However, if some observations are known to be clustered beforehand, this information should be used. This occurs, for example, in timecourse experiments, where each `subject' is observed repeatedly over time or another covariate. An investigator may wish to cluster \emph{subjects} with similar linear trends over time. Hence, all observations corresponding to a single subject should always be grouped together. Grouping observations {\it a priori} may decrease the variance of the profile posterior distribution, and/or greatly reduce the complexity of MAP estimation. A grouping factor may be passed to \code{profLinear} using the \code{group} argument. 

\section[Examples]{Examples: \code{profBinary}} \label{Examples:profBinary}
The following \proglang{R} code chunk simulates a multiple binary outcome dataset. The cells of each row in the dataset correspond to multiple binary observations on a single `subject'.
<<>>=
#simulate three subgroups probabilities
p1 <- c(0.05, 0.05, 0.05)
p2 <- c(0.95, 0.05, 0.05)
p3 <- c(0.95, 0.95, 0.05)
p4 <- c(0.95, 0.95, 0.95)
y1 <- matrix(rbinom(99, 1, p1), 33, 3, TRUE)
y2 <- matrix(rbinom(99, 1, p2), 33, 3, TRUE)
y3 <- matrix(rbinom(99, 1, p3), 33, 3, TRUE)
y4 <- matrix(rbinom(99, 1, p4), 33, 3, TRUE)
y  <- rbind(y1, y2, y3, y4)

#fit the binary model
fitb <- profBinary(y)
@

The \code{pci} function may again be used to quantify the agreement between the simulated and estimated partitions.
<<>>=
simulatedPartB <- rep(1:4, rep(33,4))
estimatedPartB <- fitb$clust
pci(simulatedPartB, estimatedPartB)
@

As mentioned above, the outcome probabilities for each cluster are beta distributed {\it a posteriori}. The parameters of the posterior distributions may be accessed in the return value of \code{profBinary}. For example, the following \proglang{R} code block computes and prints the posterior mean for the outcome probabilities in each cluster.
<<>>=
attach(fitb, warn.conflicts=FALSE)
for(i in 1:length(a)) {
    sizes <- format(table(clust), digits=2)
    probs <- format(a[[i]]/(a[[i]]+b[[i]]), digits=2, nsmall=3L)
    probs <- paste(probs, collapse=" ")
    cat(paste("cluster:", i, "size:", sizes[i], "mean:", probs, "\n"))
}
detach(fitb)
@
\section[Extensions]{Extensions} \label{Extensions}
The \pkg{profdpm} package is currently limited to product partitions of linear and binary models, and the MAP estimators described above. However, the package was designed to promote efficiency and extensibility. Hence, the \pkg{profdpm} package has potential to develop along with the DPM and PPM literature. Estimating a partition is computationally intensive, and remains an active area of computational research. Other aspects of partition estimation are also under scrutiny. For example, recent work by \citep{WangDunson2010} suggest that MAP estimators may yield extraneous clusters in partition estimates. The authors recommend optimizing a pseudo marginal likelihood (PML), which imposes a leave-one-out cross-validation strategy to penalize extraneous clusters in partition estimates. The \pkg{profdpm} has potential to accommodate such novel optimization criteria, in addition to newer computational methods.


\bibliography{profdpm}
\end{document}
