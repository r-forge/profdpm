\documentclass[article]{jss}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\VignetteIndexEntry{profdpm}
%% almost as usual
\author{Matthew S. Shotwell\\Vanderbilt University}
\title{\pkg{profdpm}: An \proglang{R} Package for MAP Estimation in a Class of Product Partition Models}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Matthew S. Shotwell} %% comma-separated
\Plaintitle{profdpm: An R Package for MAP Estimation in a Class of Product Partition Models} %% without formatting
%\Shorttitle{MAP Estimation in a Class of Product Partition Models} %% a short title (if necessary)

%% an abstract and keywords
\Abstract{
The \pkg{profdpm} package facilitates profile inference, or inference at the posterior mode for a class of product partition models (PPM). The Dirichlet process mixture is represented as a specific case in this class, and is the default. The PPM is implemented for linear models and multivariate binary models. Several methods are implemented to search for the maximum posterior estimate of the data partition. This article discusses the relevant theory, the \proglang{R} and \proglang{C} implementation, and examples of high level functionality.
}
\Keywords{product partition model, MAP estimate, clustering, \proglang{R}, \proglang{C}}
\Plainkeywords{product partition model, MAP estimate, clustering, R, C} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
  Matthew S. Shotwell\\
  Department of Biostatistics\\
  Vanderbilt University\\
  1161 $21^{\mathrm{st}}$ Ave. South, Nashville, TN\\
  E-mail: \email{matt.shotwell@Vanderbilt.edu}\\
  URL: \url{http://biostat.mc.vanderbilt.edu/wiki/Main/MattShotwell}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsbsy}
\newcommand{\bz}{\boldsymbol{z}}
\newcommand{\bu}{\boldsymbol{u}}
\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bPhi}{\boldsymbol{\Phi}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\bXp}{\boldsymbol{X}^{\prime}}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\bX}{\boldsymbol{X}}
\newcommand{\bI}{\boldsymbol{I}}
\newcommand{\byp}{\boldsymbol{y}^{\prime}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\bv}{\boldsymbol{v}}
\newcommand{\bm}{\boldsymbol{m}}
\newcommand{\bS}{\boldsymbol{S}}

\begin{document}

\section[Intro]{Introduction}
\pkg{profdpm} is an extension package for the \proglang{R} language and environment for statistical computing \citep{R2010}. This package facilitates profile inference, or inference at the posterior mode in a class of product partition models (PPM). The class of PPMs considered was motivated by a PPM formulation of the Dirichlet process mixture, which is a special case. The \pkg{profdpm} package consists of two model-fitting functions, \code{profBinary} and \code{profLinear}, and a function \code{pci} that computes several metrics of agreement between two partitions.

The remainder of this article proceeds as follows: the relevant theory of product partition models is discussed in section \ref{PPMs}, \proglang{R} functions and the underlying \proglang{C} methods are outlined in section \ref{Code}, and examples are presented in sections \ref{Examples:profLinear} and \ref{Examples:profBinary}. Section \ref{Extensions} gives a short discussion of potential extensions to the \pkg{profdpm} package.\\

\section[PPMs]{Product partition models} \label{PPMs}
Consider the following hierarchical Bayesian model for a collection of possibly multivariate observations $\by = \{y_1, \ldots, y_n\}$:
\begin{eqnarray}
y_i | z_i = k, \phi_k & \sim & f(y_i|\phi_k) \nonumber \\
\phi_k & \sim & \pi_{\phi}(\phi_k) \nonumber \\
\bz & \sim & \pi_{\bz}(\bz) \propto \prod_{k=1}^r c_k(\bz), \nonumber
\end{eqnarray}
where $\bz = \{z_1, \ldots, z_n\}$ is a collection of cluster membership variables such that $z_i = k$ indicates observation $i$ is a member of cluster $k$. The collection $\bz$ represents a partition of $\by$ into $r$ clusters, identified by the $r$ unique values among $\bz$. The values of $\bz$ are not important, as long as they are distinct. For simplicity, the positive integers are used to enumerate the distinct values. The function $f$ is a probability density indexed by parameter $\phi_k$. For $k = 1,\ldots,r$, $\phi_k$ are independently distributed according to prior density $\pi_{\phi}$. The prior mass function $\pi_{\bz}$ is proportional to a product of {\it cohesion} functions $c_k$. The cohesion functions are used to specify the prior distribution and prior belief about the data partition. The Dirichlet process mixture has a PPM representation when $c_k(\bz) = \alpha\Gamma(n_k)$, where $\alpha$ is a scalar `precision' parameter, $\Gamma$ is the gamma function, and $n_k$ represents the number of observations assigned to the $k^{th}$ cluster. Alternative cohesions yield other well-known process mixtures \citep[for a partial listing, see][]{LauGreen2007}. The \pkg{profdpm} package extends the Dirichlet process mixture cohesion to include a scalar `balance' parameter $\lambda$, such that $c_k(\bz) = \alpha\Gamma(n_k)^{\lambda}$. The value of $\lambda$ affects the balance of partition cluster sizes $\{n_1, \ldots, n_r\}$. The posterior distribution over the data partition is proportional to the product
\begin{eqnarray}
p(\bz|\by) \propto \prod_{k=1}^r c_k(\bz) \int L(\phi_k|\by) \pi_{\phi}(\phi_k) d\phi_k , \label{eqn:posterior}
\end{eqnarray}
where $L(\phi_k|\by) = \prod_{i=1}^n f(y_i|\phi_k)^{I(z_i=k)}$ is the cluster-specific likelihood. Hence, the product partition model is conjugate in the sense that both prior and posterior may be written as a product of cluster-specific terms. The product partition model is attributed to \citet{Hartigan1990} and \citet{BarryHartigan1992}.

A maximum {\it a posteriori} (MAP) estimate of the data partition variable $\bz$ is often computed when the PPM is used for clustering. However, the principal difficulty with partition models is the size of the partition space \citep[see the `Bell number',][]{Bell1934, Rota1964}. Hence, computing the MAP estimate using enumerative methods is not practical.

The \pkg{profdpm} package utilizes three methods to approximate the MAP estimate in an iterative fashion. The first method is the agglomerative method of \citet{Ward1963}, later used by \citet{Heard2005} in the context of Dirichlet process mixtures. The agglomerative method is usually the fastest of the three implemented methods, but does not yield arbitrarily precise approximations to the MAP estimate.

The second method is the Polya urn Gibbs sampler of \citet{MacEachern1994}, \citet{BushMacEachern1996}, and \citet{MacEachernMuller1998}. The Gibbs sampler sequentially samples from the full conditional distributions having mass functions of the form $p(z_i|\bz_{-i},\by)$, where $\bz_{-i}$ is the collection of cluster membership variables with the exception of $z_i$. The Gibbs method produces a consistent sequence of MAP estimates by selecting the sample MAP estimate following each iteration. However, the Polya urn Gibbs sampler is prone to poor mixing in the partition space, and is computationally intensive.

The last method is an iterative stochastic search utilizing `explode' and `merge' operations on the clusters of a partition. At the explode step, a randomly selected subset of observations are redistributed uniformly at random to an existing or new cluster. Each of the exploded observations are then merged with one of the existing clusters in a sequentially optimal fashion. The explode-merge method is motivated by the split-merge Metropolis Hastings algorithms of \citet{GreenRichardson2001}, and \citet{JainNeal2004, JainNeal2007}. This method utilizes a Markov chain to approximate the MAP estimate, but does not sample from the posterior distribution over the data partition. Hence, the explode-merge method avoids the complexity and computational expense of ensuring the chain is ergodic. 

Profile inference about the parameter $\phi_k$ is conditional on an estimate of the data partition. Conditional on the estimate, $\{\phi_1, \ldots, \phi_r\}$ are independent {\it a posteriori}, and distributed according to 
\begin{displaymath}
p(\phi_k | \by, \hat{\bz}) = \int L(\phi_k|\by) \pi_{\phi}(\phi_k) d\phi_k.
\end{displaymath}
The likelihood and prior over $\phi_k$ are often selected to be conjugate in $\phi_k$, giving this integral a convenient form. The PPMs used in the \pkg{profdpm} package are two such models.

\section[Code]{Programming strategy} \label{Code}

The \pkg{profdpm} package computes a MAP estimate for two types of PPMs, corresponding to the \code{profLinear} and \code{profBinary} functions. Both functions accept data and model fitting arguments, and return an estimate of the data partition and other information necessary for profile inference. 

\subsection[R code]{\proglang{R} code}

The \code{profLinear} function fits a product partition of conjugate normal linear models:
\begin{eqnarray}
y_i | \bx_i, z_i = k, \bmu_k, \tau_k & \sim & N(\bx^{\prime}\bmu_k, \tau_k) \nonumber \\
\bmu_k, \tau_k & \sim & N_qG(\bm_0, s_0I_q, a_0/2, 2/b_0) \nonumber \\
\bz & \sim & \pi_{\bz}(\bz) \propto \prod_{k=1}^r \alpha \Gamma(n_k)^{\lambda},
\end{eqnarray}
where $y_i$ is a continuous scalar observation, $\bx_i$ is a covariate vector, $N$ represents the normal distribution with mean $\bx^{\prime}\bmu_k$ and precision $\tau_k$, and $N_qG$ represents the $(q+1)$-variate normal-gamma distribution with mean $\bm_0$, precision matrix $\tau s_0I_q$, shape $a_0/2$, and scale $2/b_0$. The prior parameters $\bm_0$, $s_0$, $a_0$, $b_0$, $\alpha$, and $\lambda$ may be specified as arguments to the \code{profLinear} function. Conditional on an estimated partition, the pairs $\{(\bmu_1, \tau_1), \ldots, (\bmu_r, \tau_r)\}$ are independent {\it a posteriori} and distributed according to the $(q+1)$-variate normal gamma distribution with mean $\bm_k$, precision matrix $\tau\bS_k$, shape $a_k/2$, and scale $2/b_k$. In addition to the estimated partition, the posterior statistics $\bm_k$, $\bS_k$, $a_k$, and $b_k$ are returned by \code{profLinear} for each cluster.

The \code{profBinary} function fits a product partition of conjugate binary models:
\begin{eqnarray}
y_{ij} | z_i = k, \phi_{kj} & \sim & B(\phi_{kj}) \nonumber \\
\phi_{kj} & \sim & \beta(a_0, b_0) \nonumber \\
\bz & \sim & \pi_{\bz}(\bz) \propto \prod_{k=1}^r \alpha \Gamma(n_k)^{\lambda},
\end{eqnarray}
where $y_{ij}$ for $j = 1,\ldots,q$ is the $j^{th}$ binary observation for a subject $i$, $B$ represents the Bernoulli distribution with probability $\phi_{kj}$, and $\beta$ represents the beta distribution with shape parameters $a_0$ and $b_0$. Conditional on an estimated partition, $\phi_{kj}$ are independently beta distributed {\it a posteriori} with shape parameters $a_{kj}$ and $b_{kj}$. The \code{profBinary} function returns the estimated data partition as well as the posterior statistics $a_{kj}$ and $b_{kj}$.

\subsection[C code]{\proglang{C} code}

The \pkg{profdpm} package implements the product partition model as a state machine. The model state may be simple or complex, depending on the resources of the target platform and the available programming effort. A simple model state might store only the original data arrays, an array of cluster membership variables, and various scalars to hold array dimensions and other required parameters. The corresponding posterior mass function must compute each term in equation \ref{eqn:posterior}, and any intermediate quantities at every evaluation. Hence, this state is memory efficient at the expense of additional computation. 

Increasingly complex model states (and code) generally result in reduced computational burden. For example, linear models with covariate vector $\bx_i$ often involve the outer product $\bx_i\bx_i^{\prime}$. A computationally efficient method would compute and store this quantity once, rather than recompute the quantity on demand. Furthermore, since $\bx_i\bx_i^{\prime}$ is symmetric, only the upper or lower triangular portion needs storage. The PPM of linear models implemented in the \pkg{profdpm} package utilizes both optimizations. 

The balance between model state complexity and computational efficiency is a matter for experimentation. The \pkg{profdpm} package leaves the programmer free to experiment by offering a uniform interface to the partition estimation methods.

The \pkg{profdpm} package implements three methods for partition estimation (see section \ref{PPMs}). Each utilizes a Markov-like process. That is, a model state is initialized and updated sequentially, where the updated state depends on the previous state. Each estimation algorithm decomposes into two simple operations on the initialized model state: reassigning a single observation from one cluster to another, and computing the marginal posterior mass at the current partition estimate. In practice, the `move' operation is further decomposed into `add' and `sub' operations to accommodate model state initialization.  

Manipulating the model state with simple operations is strategic. By implementing a few simple operations efficiently, the estimation routines may be written with emphasis on simplicity and correctness. In addition, generic application of the estimation routines is reduced to implementing just two simple operations for each new PPM ({\it e.g.} for product partitions of linear or binary models).
 
 The posterior mass function in a PPM is a product of cluster specific terms. Hence, moving a single observation from one cluster to another affects two of these terms at most. The posterior mass calculation is optimized by computing only the terms associated with clusters modified since the previous calculation. The optimization is implemented by decomposing the calculation into operations that compute only the cluster-specific terms, and an operation that computes cluster-independent terms. Computing posterior mass at a given partition state is further simplified by selecting a conjugate likelihood and prior, since the posterior mass function then has a simplified form. However, nonconjugate models are equally applicable, provided the posterior mass is computable by numerical means.

Each supported PPM has an associated \proglang{C} structure containing data arrays, variables for model fitting parameters, and pointers to functions that perform the simple operations necessary for estimation. These structures hold the partition state, and their references are passed to and from the estimation methods. Additional PPMs may be supported by defining new state structures and the associated simple operations. Readers interested in extending the \pkg{profdpm} package are encouraged to explore the \pkg{profdpm} source code, available in the supplementary material. The PPM of binary models implementation (\code{src/pdpmbm.c}) is the simplest of the two implemented models.

\section[Examples]{Examples: \code{profLinear}} \label{Examples:profLinear}
This code example simulates a dataset consisting of three linear subgroups. The goal of this analysis is to recover the subgroup partition and perform profile inference on the slope parameter of each cluster. The following \proglang{R} code block creates and fits the simulated dataset. To establish reproducible results, the pseudo random number generator seed is fixed. However, repeating this example without the fixed seed is useful for guaging variability in the MAP estimate, which may be considerable.
<<echo=FALSE>>=
options(prompt = "R> ")
options(continue = "R+ ")
@
<<>>=
set.seed(42)

#simulate data with 3 linear subgroups
x <- as.matrix(runif(99))
y <- c(0*x[1:33], 10*x[34:66], 20*x[67:99]) + rnorm(99)
#estimate linear partition
library("profdpm")
fit1 <- profLinear(y ~ 0 + x)
@
Figure~\ref{fig:sim1} presents the simulated data in a scatterplot. For each cluster identified in the estimated partition, the profile posterior mean slope is represented by a dashed line with intercept zero. A $95\%$ credible interval for the slope is represented by two solid lines with slopes corresponding to the $0.025$ and $0.975$ quantiles of the profile posterior distribution over the slope parameter. These quantiles are computed using a parametric bootstrap.
<<label=figSim1, include=FALSE>>=
plot(x, y)
#plot mean line, bootstrap 95% credible lines
B <- 10000 #bootstrap size
attach(fit1, warn.conflicts=FALSE)
for(i in 1:length(m)) {
    abline(a=0,b=m[[i]],lty=2, col=i)
    tboot <- rgamma(B, a[[i]]/2, b[[i]]/2)
    mboot <- rnorm(B, m[[i]], 1/sqrt(s[[i]]*tboot))
    qboot <- quantile(mboot, probs=c(0.025, 0.975))
    abline(a=0,b=qboot[1], col=i)
    abline(a=0,b=qboot[2], col=i)
}
detach(fit1)
@

\begin{figure}[h!]
\begin{center}
<<fig=TRUE, echo=FALSE>>=
<<figSim1>>
@
\end{center}
\caption{Scatterplot of three simulated linear subgroups. Mean estimates (dashed) and $95\%$ credible intervals (solid) are presented, conditional on the data partition estimated using the \code{profLinear} function. \label{fig:sim1}}
\end{figure}

The \code{profLinear} function may also accommodate nonlinear subgroups, under suitable transformations of the covariate. The following example simulates two subgroups with nonlinear mean functions.
<<>>=
#simulate data with 2 non-linear subgroups
sinc <- function(x) sin(pi*x)/(pi*x)
x <- as.matrix(runif(100))
y <- c(20*sinc(2*x[1:50]), 20*sinc(5*x[51:100]))+rnorm(100)
X <- cbind(sinc(2*x), sinc(5*x))

#estimate partition
library("profdpm")
fit2 <- profLinear(y ~ 0 + sinc(2*x) + sinc(5*x))
@

The following code block generates the scatterplot presented in Figure~\ref{fig:sim2}. The plot is overlaid with the profile posterior mean functions for each cluster. A pointwise $95\%$ credible interval for each mean function is computed using a parametric bootstrap.
<<label=figSim2, include=FALSE>>=
plot(x, y)
#plot mean curve, bootstrap 95% credible lines
B <- 10000 #bootstrap size
attach(fit2, warn.conflicts=FALSE)
for(i in 1:length(m)) {
    xplot <- seq(0.001, 1, length.out=100)
    mplot <- cbind(sinc(2*xplot), sinc(5*xplot)) %*% m[[i]]
    tboot <- rgamma(B, a[[i]]/2, b[[i]]/2)
    mboot <- matrix(rnorm(2*B, 0, 1/sqrt(tboot)),ncol=2)
    mboot <- mboot %*% chol(solve(s[[i]])) 
    mboot <- mboot + outer(rep(1,B),m[[i]])
    Xplot <- cbind(sinc(2*xplot), sinc(5*xplot))
    Mplot <- mboot %*% t(Xplot)
    Cred  <- apply(Mplot, 2, quantile, probs=c(0.025,0.975))
    lines(xplot, mplot, col=i, lty=2)
    lines(xplot, Cred[1,], col=i, lty=1)
    lines(xplot, Cred[2,], col=i, lty=1)
}
detach(fit2)
@

\begin{figure}[h!]
\begin{center}
<<fig=TRUE, echo=FALSE>>=
<<figSim2>>
@
\end{center}
\caption{Scatterplot of two simulated nonlinear subgroups. Mean estimates (dashed) and $95\%$ credible intervals (solid) are presented, conditional on the data partition estimated using the \code{profLinear} function. \label{fig:sim2}}
\end{figure}

In the examples above, the \code{pci} function may be used to compute several measures of agreement between the simulated and estimated partitions. The following demonstrates the use of \code{pci}.
<<>>=
simulatedPart1 <- rep(1:3, rep(33,3))
estimatedPart1 <- fit1$clust
pci(simulatedPart1, estimatedPart1)
simulatedPart2 <- rep(1:2, rep(50,2))
estimatedPart2 <- fit2$clust
pci(simulatedPart2, estimatedPart2)
@

The first value in the vector returned by \code{pci} corresponds to the \citet{Rand1971} index for the two partitions. This statistic enumerates the proportion of observations pairs that are clustered concordantly in the two partitions. A Rand index value of one indicates perfect agreement. Inference about these statistics is difficult, partly because a null hypothesis about the partition is rarely well defined. However, the \code{pci} function may be used to construct bootstrap tests using the Rand index (or another index) as a test statistic.

In the previous examples, every observation is clustered individually. However, if some observations are known to be clustered beforehand, this information may be used. This might occur, for example in timecourse experiments where subjects are observed repeatedly. When the objective is a partition of \emph{subjects}, all observations corresponding to a single subject should be clustered together automatically. Grouping observations {\it a priori} may decrease the variance of the profile posterior distribution, and/or greatly reduce the complexity of MAP estimation. A prior grouping factor may be passed to \code{profLinear} using the \code{group} argument. 


\section[Examples]{Examples: \code{profBinary}} \label{Examples:profBinary}
The following \proglang{R} code block simulates a multiple binary outcome dataset with four latent subgroups. The cells of each row in the dataset correspond to multiple binary observations on a single `subject'. The \code{profBinary} function automatically clusters all observations in a single row. However, the \code{group} argument may be used to specify further grouping {\it a priori}.
<<>>=
#simulate three subgroups probabilities
p1 <- c(0.05, 0.05, 0.05)
p2 <- c(0.95, 0.05, 0.05)
p3 <- c(0.95, 0.95, 0.05)
p4 <- c(0.95, 0.95, 0.95)
y1 <- matrix(rbinom(99, 1, p1), 33, 3, TRUE)
y2 <- matrix(rbinom(99, 1, p2), 33, 3, TRUE)
y3 <- matrix(rbinom(99, 1, p3), 33, 3, TRUE)
y4 <- matrix(rbinom(99, 1, p4), 33, 3, TRUE)
y  <- rbind(y1, y2, y3, y4)

#fit the binary model
fitb <- profBinary(y)
@

The \code{pci} function may again be used to quantify the agreement between the simulated and estimated partitions for the multivariate binary data.
<<>>=
simulatedPartB <- rep(1:4, rep(33,4))
estimatedPartB <- fitb$clust
pci(simulatedPartB, estimatedPartB)
@

As mentioned above, the outcome probabilities for each cluster are independently beta distributed {\it a posteriori}. The parameters of the profile posterior distribution for each cluster may be accessed in the return value of \code{profBinary}. For example, the following \proglang{R} code block computes and prints the profile posterior mean for the outcome probabilities in each cluster.
<<>>=
attach(fitb, warn.conflicts=FALSE)
for(i in 1:length(a)) {
    sizes <- format(table(clust), digits=2)
    probs <- format(a[[i]]/(a[[i]]+b[[i]]), digits=2, nsmall=3L)
    probs <- paste(probs, collapse=" ")
    cat(paste("cluster:", i, "size:", sizes[i], "mean:", probs, "\n"))
}
detach(fitb)
@

\newpage
\section[Extensions]{Extensions} \label{Extensions}
The \pkg{profdpm} package is currently limited to product partitions of linear and binary models, and the MAP estimators described above. However, the package was designed to promote efficiency, extensibility, and develop along with the DPM and PPM literature. Estimating a partition is computationally intensive, and remains an active area of computational research. Other aspects of partition estimation are also under scrutiny. For example, recent work by \citet{WangDunson2010} suggest that marginal likelihood optimization may yield extraneous clusters in partition estimates. The authors recommend a pseudo marginal likelihood (PML) approach, which imposes a leave-one-out cross-validation strategy to penalize extraneous clusters in partition estimates. The \pkg{profdpm} has potential to accommodate such novel optimization criteria, in addition to newer computational methods.

\section*{Acknowledgments}
This research was partly funded by the following National Institutes of Health, National Institute of General Medical Sciences, and National Science Foundation funding projects: NIH 1T32GM074934, NIH R03CA137805, NSF DMS0604666, NIH P20RR017696.

\bibliography{profdpm}
\end{document}
